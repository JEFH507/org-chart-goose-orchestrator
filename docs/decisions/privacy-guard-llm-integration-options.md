# Privacy Guard LLM Integration Options

**Date:** 2025-11-06  
**Status:** Decision Pending  
**Context:** Phase 5 H6 - Privacy Guard integration with goose  

---

## Problem Statement

**Current Architecture Flaw:**
```
User types "My SSN is 123-45-6789"
    ‚Üì
goose sends to LLM (OpenRouter) ‚Üê ‚ö†Ô∏è PII LEAKED
    ‚Üì
LLM decides to call Privacy Guard MCP tool
    ‚Üì
Privacy Guard masks PII
    ‚Üì
Too late - LLM already saw raw PII
```

**Root Cause:** MCP tools are called BY the LLM, not BEFORE the LLM sees user input.

**Your Insight:**
> "Note: I am guessing here is where we were wrong: OpenRouter ‚Üí Privacy Guard MCP as is not goose 
> the one that reads the message and send to mcp, but goose send message to llm, and the the llm 
> use tool calling for calling the mcp...so at that point the llm already saw the unedited message."

**Business Requirement:** Enterprise users need PII protection WITHOUT requiring expensive local LLM hardware.

---

## Solution Options Summary

| # | Solution | Effort | Time | Fork? | Protects PII? | Production? |
|---|----------|--------|------|-------|---------------|-------------|
| 1 | **Privacy Guard Proxy** | Low | 1-2 weeks | ‚úÖ No | ‚úÖ Yes | ‚ö†Ô∏è Beta |
| 2 | **goose Desktop Fork** | Med | 2-3 weeks | ‚ùå Yes | ‚úÖ Yes | ‚úÖ Yes |
| 3 | **Standalone UI Client** | High | 4-6 weeks | ‚úÖ No | ‚úÖ Yes | ‚úÖ Yes |
| 4 | **CLI Wrapper (Validation)** | Low | 1 day | ‚úÖ No | ‚úÖ Yes | ‚ùå No |
| 5 | **HTTP API Only** | Low | Done | ‚úÖ No | ‚ùå NO | ‚ùå No |

---

## Option 1: Privacy Guard Proxy Server ‚≠ê RECOMMENDED FOR QUICK WIN

### Architecture
```
User Input
    ‚Üì
goose Desktop
    ‚Üì
[Privacy Guard Proxy] (localhost:8090) ‚Üê INTERCEPTS HTTP HERE
    ‚Üì (scans ‚Üí masks ‚Üí forwards)
OpenRouter API (only sees masked text: "My SSN is SSN_a1b2c3d4")
    ‚Üì
LLM processes masked version
    ‚Üì
Response ‚Üí Proxy ‚Üí Unmasks tokens ‚Üí User sees real data
```

### How It Works
1. **User types:** "My SSN is 123-45-6789"
2. **goose Desktop sends** HTTP POST to http://localhost:8090/api/v1/chat/completions (proxy, not OpenRouter)
3. **Proxy intercepts:**
   - Calls Privacy Guard: `POST localhost:8089/guard/scan` ‚Üí detects SSN
   - Calls Privacy Guard: `POST localhost:8089/guard/mask` ‚Üí gets "My SSN is SSN_a1b2c3d4"
   - Stores mapping: `{session_id: {..., "SSN_a1b2c3d4": "123-45-6789"}}`
4. **Proxy forwards** masked text to OpenRouter
5. **OpenRouter/LLM** never sees real SSN ‚úÖ
6. **Response comes back** from LLM
7. **Proxy unmasks** any tokens in response
8. **User sees** real data (transparent)

### Implementation

**Files:**
```
src/privacy-guard-proxy/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ server.ts              # Express server (main intercept logic)
‚îÇ   ‚îú‚îÄ‚îÄ privacy-client.ts      # HTTP client for Privacy Guard API
‚îÇ   ‚îú‚îÄ‚îÄ token-store.ts         # In-memory token mapping
‚îÇ   ‚îú‚îÄ‚îÄ config.ts              # Configuration
‚îÇ   ‚îî‚îÄ‚îÄ types.ts               # TypeScript interfaces
‚îú‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ tsconfig.json
‚îú‚îÄ‚îÄ Dockerfile
‚îî‚îÄ‚îÄ README.md
```

**Core Logic:**
```typescript
// src/server.ts
import express from 'express';
import { PrivacyGuardClient } from './privacy-client';
import { TokenStore } from './token-store';

const app = express();
const privacy = new PrivacyGuardClient('http://localhost:8089');
const tokens = new TokenStore();

app.post('/api/v1/chat/completions', async (req, res) => {
  const { messages } = req.body;
  const userMsg = messages[messages.length - 1].content;
  
  // Scan for PII
  const scan = await privacy.scan(userMsg);
  
  if (scan.detections.length > 0) {
    // Mask PII
    const masked = await privacy.mask(userMsg);
    const sessionId = masked.session_id;
    
    // Store tokens for unmask
    tokens.store(sessionId, masked.redactions);
    
    // Replace message
    messages[messages.length - 1].content = masked.masked_text;
    
    // Forward to OpenRouter
    const llmResp = await fetch('https://openrouter.ai/api/v1/chat/completions', {
      method: 'POST',
      headers: req.headers,
      body: JSON.stringify({ ...req.body, messages })
    });
    
    // Unmask response
    let content = llmResp.data.choices[0].message.content;
    content = tokens.unmask(sessionId, content);
    
    // Clean up
    tokens.delete(sessionId);
    
    res.json({ ...llmResp.data, choices: [{ message: { content }}]});
  } else {
    // No PII, pass through
    const llmResp = await fetch('https://openrouter.ai/api/v1/chat/completions', {
      method: 'POST',
      headers: req.headers,
      body: JSON.stringify(req.body)
    });
    res.json(llmResp.data);
  }
});

app.listen(8090);
```

**goose Configuration:**
```yaml
# ~/.config/goose/config.yaml
GOOSE_PROVIDER__OPENROUTER_BASE_URL: http://localhost:8090/api/v1
PRIVACY_GUARD_ENABLED: true
```

### Pros
- ‚úÖ No goose fork needed
- ‚úÖ Works with current goose Desktop
- ‚úÖ Fast to implement (1-2 days coding)
- ‚úÖ Toggleable (change URL to disable)
- ‚úÖ Transparent UX
- ‚úÖ LLM never sees raw PII

### Cons
- ‚ö†Ô∏è Adds latency (~50-200ms per request)
- ‚ö†Ô∏è Requires running separate service
- ‚ö†Ô∏è Need to handle multiple LLM providers (OpenRouter, Anthropic, OpenAI)
- ‚ö†Ô∏è Token store must be memory-only (security)

### Validation
- Use existing 50/50 integration tests
- Add proxy-specific tests for mask/unmask
- Benchmark latency impact
- Security audit of token storage

**Effort:** 1-2 weeks  
**Maintenance:** Low (stable API)

---

## Option 2: goose Desktop Fork with Privacy Layer

### Architecture
```
User Input (ChatInput.tsx)
    ‚Üì
[Privacy Guard Hook] ‚Üê INTERCEPTS IN UI CODE
    ‚Üì (scans ‚Üí masks before submit)
Masked Text ‚Üí goose Backend ‚Üí OpenRouter
    ‚Üì
LLM processes masked version (never sees PII)
    ‚Üì
Response ‚Üí Unmask ‚Üí Display
```

### How It Works
1. **User types** in goose Desktop chat input
2. **Before submit**, React component calls Privacy Guard
3. **Privacy Guard** scans and masks in UI layer
4. **goose backend** only receives masked text
5. **OpenRouter/LLM** never sees raw PII ‚úÖ

### Implementation

**Fork:** `https://github.com/block/goose` ‚Üí `goose-org-twin-ui`

**Files to Modify:**
```
goose-desktop/ (forked)
‚îú‚îÄ‚îÄ src/ui/
‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ChatInput.tsx        # MODIFY: Add Privacy Guard hook
‚îÇ   ‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ privacy-guard.ts     # NEW: Privacy Guard HTTP client
‚îÇ   ‚îú‚îÄ‚îÄ settings/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ PrivacySettings.tsx  # NEW: Privacy Guard config UI
‚îÇ   ‚îî‚îÄ‚îÄ types/
‚îÇ       ‚îî‚îÄ‚îÄ privacy.ts           # NEW: TypeScript types
```

**Code Changes:**
```typescript
// src/ui/components/ChatInput.tsx (MODIFIED)
import { usePrivacyGuard } from '../lib/privacy-guard';

export function ChatInput() {
  const { scan, mask, enabled } = usePrivacyGuard();
  const [showPiiWarning, setShowPiiWarning] = useState(false);
  
  async function handleSubmit(message: string) {
    if (enabled) {
      // Scan for PII
      const scanResult = await scan(message);
      
      if (scanResult.detections.length > 0) {
        // Show notification
        setShowPiiWarning(true);
        
        // Mask PII
        const masked = await mask(message);
        message = masked.masked_text;
        
        // Log for audit
        console.log(`üîí Masked ${scanResult.detections.length} PII items`);
      }
    }
    
    // Send to goose backend (masked if PII found)
    await goose.sendMessage(message);
  }
  
  return (
    <div>
      {showPiiWarning && <Alert>üîí PII detected and masked</Alert>}
      <input onSubmit={handleSubmit} />
    </div>
  );
}
```

```typescript
// src/ui/lib/privacy-guard.ts (NEW)
export class PrivacyGuardClient {
  constructor(private baseUrl = 'http://localhost:8089') {}
  
  async scan(text: string) {
    const res = await fetch(`${this.baseUrl}/guard/scan`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        text,
        mode: 'hybrid',
        tenant_id: getCurrentUser()
      })
    });
    return res.json(); // { detections: [...] }
  }
  
  async mask(text: string) {
    const res = await fetch(`${this.baseUrl}/guard/mask`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        text,
        method: 'pseudonym',
        mode: 'hybrid',
        tenant_id: getCurrentUser()
      })
    });
    return res.json(); // { masked_text, redactions, session_id }
  }
}

export function usePrivacyGuard() {
  const settings = useSettings();
  const client = new PrivacyGuardClient(settings.privacyGuardUrl);
  
  return {
    enabled: settings.privacyGuardEnabled,
    scan: client.scan.bind(client),
    mask: client.mask.bind(client)
  };
}
```

### Pros
- ‚úÖ Clean UI integration
- ‚úÖ No separate proxy service
- ‚úÖ Better UX (in-app notifications)
- ‚úÖ Can show PII detection in real-time
- ‚úÖ Settings UI for Privacy Guard config
- ‚úÖ LLM never sees raw PII

### Cons
- ‚ùå Requires fork maintenance
- ‚ùå Need to merge upstream goose changes regularly
- ‚ùå Requires Electron/TypeScript/React skills
- ‚ö†Ô∏è Delayed updates from upstream
- ‚ö†Ô∏è Fork becomes "your problem" to maintain

### Validation
- Integration tests (50/50 suite)
- UI testing (E2E with Playwright)
- Performance testing (UI responsiveness)

**Effort:** 2-3 weeks (fork setup + UI changes)  
**Maintenance:** Medium (monthly upstream merges)

---

## Option 3: Standalone UI Client ("goose Enterprise")

### Architecture
```
[Custom Electron App]
    ‚Üì
Privacy Guard (built-in middleware)
    ‚Üì
goose CLI (subprocess)
    ‚Üì
OpenRouter (only sees masked)
```

### How It Works
- Build entirely new desktop app
- Embed Privacy Guard as first-class feature
- Use goose CLI as backend (stdio communication)
- Brand as "goose Enterprise" or "Secure AI Assistant"

### Implementation

**Stack:**
- **Tauri** (Rust + WebView, lighter than Electron)
- **React/Svelte** for UI
- **goose CLI** as subprocess
- **Privacy Guard** as HTTP client

**Architecture:**
```
src/
‚îú‚îÄ‚îÄ ui/                    # React/Svelte frontend
‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ privacy.ts     # Privacy Guard integration
‚îÇ   ‚îî‚îÄ‚îÄ main.tsx
‚îú‚îÄ‚îÄ backend/               # Tauri Rust backend
‚îÇ   ‚îú‚îÄ‚îÄ goose.rs          # Subprocess management
‚îÇ   ‚îú‚îÄ‚îÄ privacy.rs        # Privacy Guard client
‚îÇ   ‚îî‚îÄ‚îÄ main.rs
‚îî‚îÄ‚îÄ config/
    ‚îî‚îÄ‚îÄ settings.json
```

### Pros
- ‚úÖ Full control over UX/features
- ‚úÖ No fork dependency on goose
- ‚úÖ Can bundle Privacy Guard + goose together
- ‚úÖ Single installer for enterprise users
- ‚úÖ Custom branding/enterprise features
- ‚úÖ LLM never sees raw PII

### Cons
- ‚ùå High development effort (4-6 weeks)
- ‚ùå Need to reimplement goose Desktop UI
- ‚ùå Slower to market
- ‚ö†Ô∏è Potential feature lag behind goose Desktop
- ‚ö†Ô∏è Full app ownership = full maintenance burden

**Effort:** 4-6 weeks (full app development)  
**Maintenance:** High (ongoing feature development)

---

## Option 4: goose CLI Wrapper Script ‚≠ê QUICK VALIDATION ONLY

### Purpose
**Validate Privacy Guard integration before building production solution**

### Implementation
```bash
#!/bin/bash
# scripts/privacy-goose.sh

set -e

PRIVACY_GUARD_URL="${PRIVACY_GUARD_URL:-http://localhost:8089}"
TENANT_ID="${TENANT_ID:-${USER}}"

# Read user input
echo "Enter your message:"
read -r USER_INPUT

# Scan for PII
SCAN_RESULT=$(curl -s -X POST "$PRIVACY_GUARD_URL/guard/scan" \
  -H "Content-Type: application/json" \
  -d "{\"text\":\"$USER_INPUT\",\"mode\":\"hybrid\",\"tenant_id\":\"$TENANT_ID\"}")

DETECTION_COUNT=$(echo "$SCAN_RESULT" | jq '.detections | length')

# Mask if PII found
if [ "$DETECTION_COUNT" -gt 0 ]; then
  echo "‚ö†Ô∏è  Detected $DETECTION_COUNT PII item(s). Masking before sending to LLM..."
  
  MASK_RESULT=$(curl -s -X POST "$PRIVACY_GUARD_URL/guard/mask" \
    -H "Content-Type: application/json" \
    -d "{\"text\":\"$USER_INPUT\",\"method\":\"pseudonym\",\"mode\":\"hybrid\",\"tenant_id\":\"$TENANT_ID\"}")
  
  MASKED_TEXT=$(echo "$MASK_RESULT" | jq -r '.masked_text')
  SESSION_ID=$(echo "$MASK_RESULT" | jq -r '.session_id')
  
  echo "üîí Masked text: $MASKED_TEXT"
  echo "üìã Session ID: $SESSION_ID"
  
  USER_INPUT="$MASKED_TEXT"
else
  echo "‚úÖ No PII detected. Sending original message."
fi

# Send to goose CLI
echo "$USER_INPUT" | goose session start
```

### Usage
```bash
chmod +x scripts/privacy-goose.sh
./scripts/privacy-goose.sh

# Example:
Enter your message:
> My SSN is 123-45-6789 and email is john@example.com

‚ö†Ô∏è  Detected 2 PII item(s). Masking before sending to LLM...
üîí Masked text: My SSN is SSN_a1b2c3d4 and email is EMAIL_x9y8z7w6
üìã Session ID: sess_12345

[goose CLI starts with masked text]
```

### Pros
- ‚úÖ Works immediately with existing tools
- ‚úÖ Zero code changes to goose
- ‚úÖ Perfect for validation/proof-of-concept
- ‚úÖ Easy to understand and modify

### Cons
- ‚ùå CLI-only (no GUI)
- ‚ùå Poor user experience (manual workflow)
- ‚ùå Not production-ready
- ‚ùå No unmask of responses

**Use Case:** Test Privacy Guard integration this week before deciding on production approach

**Effort:** 1 day  
**Maintenance:** None (throwaway)

---

## Option 5: HTTP API Only (No LLM Integration) ‚ùå NOT RECOMMENDED

### Architecture
```
Admin UI ‚Üí Controller API ‚Üí Privacy Guard
(Backend use only)

goose Desktop: Unchanged (no privacy protection)
```

### Description
- Privacy Guard exists ONLY for admin/backend tools
- goose Desktop users have NO PII protection from LLM
- Privacy Guard used for:
  - Scanning audit logs for PII
  - Masking session exports
  - Compliance reporting

### Why This Fails
**‚ùå Does NOT solve the core problem:**
- Users still send "My SSN is 123-45-6789" to OpenRouter
- LLM provider sees raw PII
- Compliance issues for enterprise
- Defeats the purpose of Privacy Guard

**Recommendation:** DO NOT USE - This option is a non-starter

---

## Recommended Execution Path

### ‚úÖ Phase 1: Return to H6.1 Validation (This Week)

**Goal:** Complete Phase 5 H workstream validation BEFORE deciding on Privacy Guard LLM integration

**Tasks:**
1. ‚úÖ H6.1 complete: 50/50 integration tests passing
2. H7: Performance validation (API latency)
3. H8: Test documentation
4. H_CHECKPOINT: Finalize tracking files

**Why:** Validate full system integration FIRST, then layer on Privacy Guard decisions

---

### ‚úÖ Phase 2: Quick Privacy Validation (Optional This Week)

**IF** you want to validate Privacy Guard concept:

**Use Option 4: CLI Wrapper Script**
- Build `scripts/privacy-goose.sh` (1 day)
- Test with real PII scenarios:
  - SSN: 123-45-6789
  - Email: john@example.com
  - Phone: 555-123-4567
  - Credit Card: 4532-1234-5678-9010
- Document masking effectiveness
- Decide if concept is sound

**Deliverables:**
- `scripts/privacy-goose.sh` (working script)
- `docs/tests/privacy-guard-validation.md` (test results)
- Decision: Does masking protect PII effectively?

---

### ‚úÖ Phase 3: Production Approach (Next Sprint)

**After Phase 1 & 2 complete, choose ONE:**

**Path A: Privacy Guard Proxy** (Recommended for speed)
- Implement `src/privacy-guard-proxy/` (1-2 weeks)
- Integrate with goose Desktop (config change)
- Deploy as systemd service
- **Time:** 2-3 weeks to production

**Path B: goose Desktop Fork** (Recommended for quality)
- Fork goose-desktop repository
- Implement Privacy Guard UI integration (2 weeks)
- Set up upstream merge strategy
- **Time:** 3-4 weeks to production

**Path C: Standalone UI** (Recommended for control)
- Design custom Electron/Tauri app (1 week)
- Implement UI + Privacy Guard (3 weeks)
- Package as installer
- **Time:** 6-8 weeks to production

---

## Decision Criteria

**Choose Option 1 (Proxy) if:**
- ‚úÖ Need production solution FAST (< 3 weeks)
- ‚úÖ Don't want to maintain goose fork
- ‚úÖ Comfortable with proxy architecture
- ‚ö†Ô∏è Can tolerate 50-200ms latency

**Choose Option 2 (Fork) if:**
- ‚úÖ Want best UX integration
- ‚úÖ Have Electron/TypeScript expertise
- ‚úÖ Can commit to upstream merges
- ‚ö†Ô∏è Okay with fork maintenance burden

**Choose Option 3 (Standalone) if:**
- ‚úÖ Need full control over product
- ‚úÖ Want custom enterprise features
- ‚úÖ Have 6+ weeks for development
- ‚ö†Ô∏è Can build/maintain full desktop app

**Use Option 4 (CLI) if:**
- ‚úÖ Just validating concept this week
- ‚ùå NOT for production use

**Avoid Option 5 (HTTP Only):**
- ‚ùå Does not protect PII in LLM requests
- ‚ùå Fails core requirement

---

## Open Questions

1. **Unmask responses?**
   - Should LLM responses containing tokens be unmasked?
   - Example: "Your SSN_a1b2c3d4 is valid" ‚Üí "Your 123-45-6789 is valid"?
   - **Risk:** Unmasked PII in audit logs

2. **Token lifespan?**
   - How long to store tokens? (Current: session-scoped, deleted after response)
   - What if user wants to reference PII later in conversation?

3. **Fallback behavior?**
   - If Privacy Guard is offline, block requests (fail-closed) or allow (fail-open)?
   - **Recommendation:** Fail-closed for compliance

4. **Multi-provider support?**
   - Proxy needs to handle OpenRouter, Anthropic, OpenAI, local Ollama
   - Each has different API format

5. **Performance targets?**
   - What latency is acceptable? 50ms? 200ms? 500ms?
   - Need benchmarks with real Privacy Guard service

---

## Next Steps

### Immediate (This Week)
1. ‚úÖ **Save this document** for reference
2. ‚úÖ **Return to H6.1 validation** (finish Phase 5 H workstream)
3. ‚ö†Ô∏è **Optional:** Build CLI wrapper for quick privacy validation
4. ‚úÖ **Document decision** after H workstream complete

### After H Workstream Complete
1. Review this document with stakeholders
2. Choose production approach (Option 1, 2, or 3)
3. Create implementation plan
4. Begin development

---

## Related Documents

- Phase 5 Technical Plan: `Technical Project Plan/master-technical-project-plan.md`
- Integration Test Results: `docs/tests/phase5-progress.md`
- Privacy Guard API: `src/privacy-guard/README.md`
- MCP Investigation: `src/privacy-guard-mcp-wrapper/README.md` (archived)

---

## Decision Log

**2025-11-06:** Document created  
**Status:** Pending - Complete H6.1 validation first  
**Next Review:** After Phase 5 H workstream complete
